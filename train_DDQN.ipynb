{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DDQN for trailer reversing\n",
    "Here we instantiate a simulation of the trailer system, and train a DDQN agent to control it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import gym\n",
    "from collections import namedtuple\n",
    "from dqn_model import DoubleQLearningModel, ExperienceReplay\n",
    "from IPython.core.debugger import set_trace\n",
    "import dqn_model\n",
    "from bicycleEnv import *\n",
    "\n",
    "#Local files. \n",
    "from visualize_combination_code import *\n",
    "from Simulate_combination_code import *\n",
    "from utility_functions import *\n",
    "from DDQNhelpers import * \n",
    "\n",
    "#dqn_model.test_calculate_q_targets(calculate_q_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU should be enough, but feel free to play around with this if you want to.\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions\n",
    "Define a set of actions $A = \\left(a_1, a_2,..., a_n \\right)$. \n",
    "\n",
    "Currently we have two potentinal control signals, velocity, \n",
    "\n",
    "$v \\in (-1, 1)$\n",
    "\n",
    "being forward and reverse, and steering angle $\\delta$ which we do not know yet how to handle. For now we let \n",
    "\n",
    "$\\delta \\in \\{-\\delta_0, 0 , \\delta_0 \\}$\n",
    "\n",
    "where $\\delta_0 \\in (-60,60)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actions are currently steering angle, where we either \n",
    "delta_0 = 45\n",
    "actions = [-delta_0, 0,delta_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a system model and run a simulation for a sanity check. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##System initial conditions. \n",
    "\n",
    "\n",
    "L = 2 #Length rear axis to front axis\n",
    "Ts = 0.01 #Sample interval in seconds. \n",
    "\n",
    "#Position x, y, and heading\n",
    "initState = (0,0, 0)\n",
    "\n",
    "#Yes, the truck is a bicycle these days. \n",
    "truck = BicycleEnv(L,Ts, initState)\n",
    "\n",
    "\n",
    "truck_pos_x = []\n",
    "truck_pos_y = []\n",
    "truck_angle = []\n",
    "\n",
    "for step_number in range(np.int(1e3)):\n",
    "    \n",
    "        #velocity = -0.1+np.sin(step_number/1e3*np.pi)\n",
    "        #steering_percentage = np.sin(step_number/1e2*np.pi)\n",
    "        steeringAngle = np.deg2rad(-45)\n",
    "        velocity  = 1\n",
    "        \n",
    "        action = (velocity, steeringAngle)\n",
    "        state  = truck.step(action) \n",
    "        \n",
    "        truck_pos_x.append(state[0])\n",
    "        truck_pos_y.append(state[1])\n",
    "        truck_angle.append(state[2])\n",
    "        #truck_rot.append(truck_rotation)\n",
    "        #trailer1_rot.append(first_trailer_rotation)\n",
    "        #trailer2_rot.append(second_trailer_rotation)\n",
    "        \n",
    "#Reset before training on network.         \n",
    "truck.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Animate data for a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from animateRectangle import* \n",
    "\n",
    "%matplotlib notebook \n",
    "\n",
    "#The previous code was put in a separate class, try it here. \n",
    "#%matplotlib tk \n",
    "fig= plt.figure()\n",
    "#ax.axis('equal')\n",
    "fig.set_dpi(100)\n",
    "fig.set_size_inches(3, 3)\n",
    "B =0\n",
    "\n",
    "rectAnim = animateRectangle(fig, B,L, truck_pos_x, truck_pos_y, truck_angle)\n",
    "\n",
    "anim = rectAnim.animate(Ts*1000)\n",
    "plt.show()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "#env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "# Enable visualization? Does not work in all environments.\n",
    "enable_visualization = False\n",
    "\n",
    "#Actions are full turn left, straight, full turn right\n",
    "#actions = (-1,0,1)\n",
    "\n",
    "\n",
    "# Initializations\n",
    "num_actions = len(actions)\n",
    "num_states = len(initState)\n",
    "\n",
    "#Training hyperparameters. \n",
    "num_episodes = 50\n",
    "batch_size = 128\n",
    "gamma = .94\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# Object holding our online / offline Q-Networks\n",
    "ddqn = DoubleQLearningModel(device, num_states, num_actions, learning_rate)\n",
    "\n",
    "# Create replay buffer, where experience in form of tuples <s,a,r,s',t>, gathered from the environment is stored \n",
    "# for training\n",
    "replay_buffer = ExperienceReplay(device, num_states)\n",
    "\n",
    "# Train\n",
    "#set_trace()\n",
    "#R, R_avg = train_loop_ddqn(ddqn, env, replay_buffer, num_episodes, enable_visualization=enable_visualization, batch_size=batch_size, gamma=gamma)\n",
    "\n",
    "#DDQNhelpers.\n",
    "#DDQNhelpers.\n",
    "#set_trace()\n",
    "R, R_avg = DDQNhelpers.train_loop_ddqn( truck, ddqn, replay_buffer, num_episodes, enable_visualization, batch_size, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDQNhelpers.train_loop_ddqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for episode in train_log: \n",
    "\n",
    "\n",
    "#print(type(episode))\n",
    "#plt.plot( episode[pos_x], episode[pos_y] )\n",
    "\n",
    "def printEpisode(episode, i ):\n",
    "    #Plot startpoint\n",
    "    plt.plot(episode.pos_x[0],episode.pos_y[0],  'bo' )\n",
    "\n",
    "    #Plot whole trajectory. \n",
    "    plt.plot( episode.pos_x, episode.pos_y, label = \"Episode \" + str(i) )\n",
    "    #legend()\n",
    "    plt.gca().legend()\n",
    "    plt.plot(episode.pos_x[-1],episode.pos_y[-1],  'kx' )\n",
    "    \n",
    "    \n",
    "    \n",
    "for i, episode in enumerate(train_log):\n",
    "    if (i%5==0):\n",
    "        printEpisode(episode,i)\n",
    "    \n",
    "#\n",
    "#episode_end = train_log[-1]\n",
    "#episode_middle = train_log[4]\n",
    "#episode_first = train_log[0]\n",
    "#\n",
    "#printEpisode(episode_end)\n",
    "#printEpisode(episode_middle)\n",
    "#printEpisode(episode_first)\n",
    "#printEpisode(train_log[1])\n",
    "#    \n",
    "    \n",
    "plt.figure() \n",
    "\n",
    "#for episode in train_log: \n",
    "#plt.plot(episode.steering_angle)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
